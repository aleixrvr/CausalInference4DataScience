{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd82bd8",
   "metadata": {},
   "source": [
    "# Propensity Score Exercise Starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368c3fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8d021",
   "metadata": {},
   "source": [
    "First we read the dataset and calculate the proportion of deaths in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f6db74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "swang1\n",
       "0    0.629682\n",
       "1    0.680403\n",
       "Name: death, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhc = pd.read_csv('rhc_dataset.csv')\n",
    "with open('confounders.yml', 'r') as f:\n",
    "    confounders = yaml.safe_load(f)\n",
    "\n",
    "rhc['swang1'] = (rhc['swang1'] == 'RHC').astype(int)\n",
    "rhc['death'] = (rhc['death'] == 'Yes').astype(int)\n",
    "rhc.groupby('swang1')['death'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae23f2",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2638d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(ps_values, swang1, name=\"\"):\n",
    "    auc = round(roc_auc_score(swang1, ps_values), 4)\n",
    "    sns.kdeplot(x=ps_values, hue=swang1, fill=True, common_norm=False, alpha=0.4).set_title(f\"AUC {name}:{auc}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518c0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    parameters = {\n",
    "        \"learning_rate\": [0.005, 0.01, 0.15, 0.2],\n",
    "        \"max_depth\":[1, 2, 3, 4, 5],\n",
    "        \"n_estimators\": [100, 150, 200, 300]\n",
    "        }\n",
    "\n",
    "#    parameters = {\n",
    "#        \"learning_rate\": [0.001, 0.01, 0.2],\n",
    "#        \"max_depth\":[1, 2, 3],\n",
    "#        \"n_estimators\": [100, 200, 300]\n",
    "#        }\n",
    "\n",
    "    grid_cv = GridSearchCV(\n",
    "        GradientBoostingClassifier(), \n",
    "        parameters, \n",
    "        scoring = \"roc_auc\",\n",
    "        cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_cv.fit(X, y)\n",
    "    return(grid_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb066a27",
   "metadata": {},
   "source": [
    "# 1. [Propensity scores first attempt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d5793",
   "metadata": {},
   "source": [
    "Train a model for the Propensity Score (PS) with the treatment variable swang1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0feb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transoforming categorical variables shouls be done inside the cross validation, and not before, because otherwise there can be some data leakage. In this exercise we did it directly for simplicity.\n",
    "\n",
    "X = rhc[confounders ]\n",
    "X = pd.get_dummies(X)\n",
    "y = rhc['swang1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca7daa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps_model = train_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Params')\n",
    "print(ps_model.best_params_)\n",
    "\n",
    "print('Best AUC')\n",
    "print(ps_model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3570a3f",
   "metadata": {},
   "source": [
    "*QUESTION*: As you can see, the AUC obtained with boosting is similar to the one obtained with logistic regression. So, why using boosting instead of logistic regression?\n",
    "\n",
    "We know they have similar AUC a posteriory. In general boosting can fit better to the data (because it provides nonlinear functions). So, if we only use logistic regression, we will not know whether we could have done better fitting using a more complex model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94e31c",
   "metadata": {},
   "source": [
    "# 2. [Overfitting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8acf0",
   "metadata": {},
   "source": [
    "Use the trained model to make predictions (probabilities) on the same dataset and calculate its AUC. Verify that the AUC with respect to the predicted probabilities is higher than the AUC reported from the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab219995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps_values = ps_model.predict_proba(X)[:, 1]\n",
    "\n",
    "plot_results(ps_values, y, name=\"Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79704948",
   "metadata": {},
   "source": [
    "Notice that the AUC calculated with the predictions is quite higher than the reported by the cross validation. The latter is a more reliable metric than the former, so we are overfitting our dataset!\n",
    "\n",
    "*NOTE*: You can try the same process with logistic regression. In that case you will see that, logistic regression overfits less or none at all. So, depending on the model you use, even you use cross validation, you will overfit more or less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9bae6",
   "metadata": {},
   "source": [
    "# 3. [Propensity scores with cross-fitting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96b04d",
   "metadata": {},
   "source": [
    "Calculate the PS using 2-fold cross-fitting: split the data set into 2 equally sized data sets $D_1$ and $D_2$. Train a model for PS using $D_1$ and predict on $D_2$, and vice versa. Calculate the AUC with the new propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf500bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_X, D2_X, D1_y, D2_y = train_test_split(X, y, test_size=0.5, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_model_boost_1 = train_model(D1_X, D1_y)\n",
    "ps_model_boost_2 = train_model(D2_X, D2_y)\n",
    "\n",
    "# We predict on the dataset D1 using the model trained on D2 and vice versa\n",
    "ps_1 = ps_model_boost_2.predict_proba(D1_X)[:, 1]\n",
    "ps_2 = ps_model_boost_1.predict_proba(D2_X)[:, 1]\n",
    "\n",
    "swang1 = pd.concat([D1_y, D2_y])\n",
    "ps_values = np.concatenate([ps_1, ps_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(swang1, ps_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae319bd",
   "metadata": {},
   "source": [
    "This is the obtained AUC with the propensity scores calculated with cross fitting, which is closer to the one obtained from the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a5f7f",
   "metadata": {},
   "source": [
    "# 4. [Visual Inspection]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0ef26",
   "metadata": {},
   "source": [
    "Make the plot of the density of the PS by treatment group. Are the two groups comparable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4afc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(ps_values, swang1, name=\"Cross fitted Boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f09ad",
   "metadata": {},
   "source": [
    "Since the support of both groups is the same, they are fully comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d9e57",
   "metadata": {},
   "source": [
    "# 5. [ATEs with T-learners and cross-fitting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef232e4",
   "metadata": {},
   "source": [
    "Calculate ATEs using T-learner & cross-fitting in order to estimate the effect of swang1 to death:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521e9c2",
   "metadata": {},
   "source": [
    "## Split the data set into 2 equally sized data sets D1 and D2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rhc[ ['swang1'] + confounders ]\n",
    "X = pd.get_dummies(X)\n",
    "y = rhc['death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e71181",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_X, D2_X, D1_y, D2_y = train_test_split(X, y, test_size=0.5, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979c7e8",
   "metadata": {},
   "source": [
    "## Take D1 and and train two models:\n",
    "\n",
    "- With swang1 = RHC, called $f_{1,R}$\n",
    "- With swang1 = Non-RHC, called $f_{1,N}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_rhc_X = D1_X[D1_X.swang1 == 1]\n",
    "data_1_rhc_y = D1_y[D1_X.swang1 == 1]\n",
    "ps_model_boost_1_rhc = train_model(data_1_rhc_X, data_1_rhc_y)\n",
    "\n",
    "data_1_nrhc_X = D1_X[D1_X.swang1 == 0]\n",
    "data_1_nrhc_y = D1_y[D1_X.swang1 == 0]\n",
    "ps_model_boost_1_nrhc = train_model(data_1_nrhc_X, data_1_nrhc_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c569dc0",
   "metadata": {},
   "source": [
    "## Repeat the process with D2 and train two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2_rhc_X = D2_X[D2_X.swang1 == 1]\n",
    "data_2_rhc_y = D2_y[D2_X.swang1 == 1]\n",
    "ps_model_boost_2_rhc = train_model(data_2_rhc_X, data_2_rhc_y)\n",
    "\n",
    "data_2_nrhc_X = D2_X[D2_X.swang1 == 0]\n",
    "data_2_nrhc_y = D2_y[D2_X.swang1 == 0]\n",
    "ps_model_boost_2_nrhc = train_model(data_2_nrhc_X, data_2_nrhc_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351e5c3",
   "metadata": {},
   "source": [
    "## Calculate on D2 the vector of predictions $f_{1,R}(x)−f_{1,N}(x)$ where x ranges for all observations in D2.\n",
    "\n",
    "Later, switch roles between D1 and D2 and calculate the ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATE_1 = ps_model_boost_2_rhc.predict_proba(D1_X)[:, 1]\n",
    "ATE_1 = ATE_1 - ps_model_boost_2_nrhc.predict_proba(D1_X)[:, 1]\n",
    "\n",
    "ATE_2 = ps_model_boost_1_rhc.predict_proba(D2_X)[:, 1]\n",
    "ATE_2 = ATE_2 - ps_model_boost_1_nrhc.predict_proba(D2_X)[:, 1]\n",
    "\n",
    "ATE_values = np.concatenate([ATE_1, ATE_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7276c0",
   "metadata": {},
   "source": [
    "The ATE is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATE_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e4f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
